base_model_name: "TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T"
train_file: "data/processed/lm_qa_pairs.jsonl"
val_file: "data/processed/lm_qa_pairs_val.jsonl"

output_dir: "models/wake_quiz_lm"
per_device_train_batch_size: 2
gradient_accumulation_steps: 8
learning_rate: 2e-4
num_train_epochs: 5
warmup_ratio: 0.1
weight_decay: 0.01
seed: 42

use_lora: true
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
target_modules:
  - "q_proj"
  - "v_proj"
